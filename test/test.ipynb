{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b318f6bb",
   "metadata": {},
   "source": [
    "# 1. download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "client = Client()\n",
    "\n",
    "# define data unit and time interval\n",
    "symbol = 'ETHUSDT'\n",
    "interval = Client.KLINE_INTERVAL_1MINUTE\n",
    "\n",
    "# define start & end date\n",
    "start_date = datetime.now() - timedelta(days=365 * 3)  # before 365 days\n",
    "end_date = datetime.now()  # current\n",
    "\n",
    "# create folder data storage\n",
    "data_folder = 'ETHUSDT'\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "\n",
    "# function save daily data to single csv\n",
    "def get_historical_data(symbol, interval, start_date, end_date):\n",
    "    # convert start & end datetime to ms\n",
    "    start_time = int(start_date.timestamp() * 1000)\n",
    "    end_time = int(end_date.timestamp() * 1000)\n",
    "\n",
    "    # extract\n",
    "    klines = client.get_historical_klines(symbol, interval, start_time, end_time)\n",
    "\n",
    "    # convert to DataFrame\n",
    "    df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "                                       'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                                       'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
    "    # convert ts to dt\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # keep only relavant\n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# download and save data \n",
    "def download_data_by_day(symbol, interval, start_date, end_date, data_folder):\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        next_date = current_date + timedelta(days=1)\n",
    "        print(f\"Downloading data from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # get daily data\n",
    "        daily_data = get_historical_data(symbol, interval, current_date, next_date)\n",
    "\n",
    "        # save to csv\n",
    "        filename = os.path.join(data_folder, f\"ethusdt_{current_date.strftime('%Y-%m-%d')}.csv\")\n",
    "        daily_data.to_csv(filename, index=False)\n",
    "\n",
    "        # update dt\n",
    "        current_date = next_date\n",
    "\n",
    "\n",
    "# data saved in 'data' folder\n",
    "download_data_by_day(symbol, interval, start_date, end_date, data_folder)\n",
    "\n",
    "\n",
    "# merge data csv\n",
    "def merge_csv_files(data_folder):\n",
    "    import glob\n",
    "\n",
    "    # get file names\n",
    "    all_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "\n",
    "    # read and merge\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# merge all csv in 'data' folder\n",
    "merged_data = merge_csv_files(data_folder)\n",
    "\n",
    "# sort by ts\n",
    "merged_data = merged_data.sort_values(by='timestamp')\n",
    "\n",
    "# save to data.csv\n",
    "merged_data.to_csv('data.csv', index=False)\n",
    "\n",
    "print(\"data is merged and sorted by time，saved in 'data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef90f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de571e56",
   "metadata": {},
   "source": [
    "# 2. strategy simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c8bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed strategies, saved results in simulations/grid80_price2400_interval1.csv\n",
      "executed strategies, saved results in simulations/grid80_price2400_interval3.csv\n",
      "executed strategies, saved results in simulations/grid80_price2400_interval5.csv\n",
      "executed strategies, saved results in simulations/grid80_price2400_interval15.csv\n",
      "executed strategies, saved results in simulations/grid80_price2700_interval1.csv\n",
      "executed strategies, saved results in simulations/grid80_price2700_interval3.csv\n",
      "executed strategies, saved results in simulations/grid80_price2700_interval5.csv\n",
      "executed strategies, saved results in simulations/grid80_price2700_interval15.csv\n",
      "executed strategies, saved results in simulations/grid80_price3000_interval1.csv\n",
      "executed strategies, saved results in simulations/grid80_price3000_interval3.csv\n",
      "executed strategies, saved results in simulations/grid80_price3000_interval5.csv\n",
      "executed strategies, saved results in simulations/grid80_price3000_interval15.csv\n",
      "executed strategies, saved results in simulations/grid80_price3300_interval1.csv\n",
      "executed strategies, saved results in simulations/grid80_price3300_interval3.csv\n",
      "executed strategies, saved results in simulations/grid80_price3300_interval5.csv\n",
      "executed strategies, saved results in simulations/grid80_price3300_interval15.csv\n",
      "executed strategies, saved results in simulations/grid100_price2400_interval1.csv\n",
      "executed strategies, saved results in simulations/grid100_price2400_interval3.csv\n",
      "executed strategies, saved results in simulations/grid100_price2400_interval5.csv\n",
      "executed strategies, saved results in simulations/grid100_price2400_interval15.csv\n",
      "executed strategies, saved results in simulations/grid100_price2700_interval1.csv\n",
      "executed strategies, saved results in simulations/grid100_price2700_interval3.csv\n",
      "executed strategies, saved results in simulations/grid100_price2700_interval5.csv\n",
      "executed strategies, saved results in simulations/grid100_price2700_interval15.csv\n",
      "executed strategies, saved results in simulations/grid100_price3000_interval1.csv\n",
      "executed strategies, saved results in simulations/grid100_price3000_interval3.csv\n",
      "executed strategies, saved results in simulations/grid100_price3000_interval5.csv\n",
      "executed strategies, saved results in simulations/grid100_price3000_interval15.csv\n",
      "executed strategies, saved results in simulations/grid100_price3300_interval1.csv\n",
      "executed strategies, saved results in simulations/grid100_price3300_interval3.csv\n",
      "executed strategies, saved results in simulations/grid100_price3300_interval5.csv\n",
      "executed strategies, saved results in simulations/grid100_price3300_interval15.csv\n",
      "executed strategies, saved results in simulations/grid120_price2400_interval1.csv\n",
      "executed strategies, saved results in simulations/grid120_price2400_interval3.csv\n",
      "executed strategies, saved results in simulations/grid120_price2400_interval5.csv\n",
      "executed strategies, saved results in simulations/grid120_price2400_interval15.csv\n",
      "executed strategies, saved results in simulations/grid120_price2700_interval1.csv\n",
      "executed strategies, saved results in simulations/grid120_price2700_interval3.csv\n",
      "executed strategies, saved results in simulations/grid120_price2700_interval5.csv\n",
      "executed strategies, saved results in simulations/grid120_price2700_interval15.csv\n",
      "executed strategies, saved results in simulations/grid120_price3000_interval1.csv\n",
      "executed strategies, saved results in simulations/grid120_price3000_interval3.csv\n",
      "executed strategies, saved results in simulations/grid120_price3000_interval5.csv\n",
      "executed strategies, saved results in simulations/grid120_price3000_interval15.csv\n",
      "executed strategies, saved results in simulations/grid120_price3300_interval1.csv\n",
      "executed strategies, saved results in simulations/grid120_price3300_interval3.csv\n",
      "executed strategies, saved results in simulations/grid120_price3300_interval5.csv\n",
      "executed strategies, saved results in simulations/grid120_price3300_interval15.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "def eth_grid_trading_strategy(file_path, output_path, nrows=None, min_price=1800, max_price=3600, grid_count=100,\n",
    "                              initial_price=2700, time_interval=3,max_size =10,grid_unit_size = 0.1,free_rate = 0.0005):\n",
    "    \"\"\"\n",
    "    grid trading strategies\n",
    "\n",
    "    parameters:\n",
    "        file_path (str): input csv file path\n",
    "        output_path (str): output csv file path \n",
    "        nrows (int, optional): number of rows to read, default=all\n",
    "        min_price (float): minimum price, default=1800\n",
    "        max_price (float): maximum price, default=3600\n",
    "        grid_count (int): number of grids, defailt=100\n",
    "        initial_price (float): initial price, default=2700。\n",
    "        time_interval (int): time interval for trade decisions, default=3 min\n",
    "        max_size : maximum trade amount\n",
    "        grid_unit_size : amount in every grid trade\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # read input data\n",
    "    df = pd.read_csv(file_path, nrows=nrows)\n",
    "\n",
    "    # generate grid points\n",
    "    grid_points = np.geomspace(min_price, max_price, grid_count)\n",
    "\n",
    "    position_2700 = np.searchsorted(grid_points, initial_price, side='right')\n",
    "\n",
    "    # strategy parameters\n",
    "    # max_position = 10  # maximum trade amount (ETH)\n",
    "    # grid_size = 0.1  # ETH amount in every grid\n",
    "\n",
    "    # new cols for recording decisions and trade amount\n",
    "    df['Decision'] = ''\n",
    "    df['Amount'] = np.nan\n",
    "    df['Position'] = 0.0  \n",
    "    df['money'] = 0.0  \n",
    "\n",
    "    # every time_interval in minute\n",
    "    df = df.iloc[::time_interval, :].reset_index(drop=True)\n",
    "\n",
    "    # calculate the dif btw each price and the grid points and decide\n",
    "    df['grid'] = np.searchsorted(grid_points, df['close'], side='right')\n",
    "\n",
    "    position = 0\n",
    "    money = 0\n",
    "    # vectorize trading logic\n",
    "    for i, row in df.iterrows():\n",
    "        price = row['close']\n",
    "        cross_grid = abs(row['grid'] - position_2700) + 1\n",
    "\n",
    "        if price <= min_price or price >= max_price:\n",
    "            df.at[i, 'Position'] = position\n",
    "            df.at[i, 'money'] = money\n",
    "            continue\n",
    "\n",
    "        # buy\n",
    "        if price < initial_price:\n",
    "            grid_size = max(1, min(max_size, cross_grid))\n",
    "            amount = grid_size * grid_unit_size\n",
    "            df.at[i, 'Decision'] = 'Buy'\n",
    "            df.at[i, 'Amount'] = amount\n",
    "            position += amount\n",
    "            money -= amount * price\n",
    "            money -= amount * price *free_rate\n",
    "\n",
    "        # sell\n",
    "        elif price > initial_price:\n",
    "            grid_size = max(1, min(max_size, cross_grid))\n",
    "            amount = grid_size * grid_unit_size\n",
    "            amount = min(position , amount)\n",
    "            if amount > 0:\n",
    "                df.at[i, 'Decision'] = 'Sell'\n",
    "                df.at[i, 'Amount'] = grid_size\n",
    "                position -= amount\n",
    "                money += amount * price\n",
    "                money -= amount * price * free_rate\n",
    "\n",
    "\n",
    "        # update position\n",
    "        df.at[i, 'Position'] = position\n",
    "        df.at[i, 'money'] = money\n",
    "\n",
    "\n",
    "    # delete misc\n",
    "    df.drop(columns=['grid'], inplace=True)\n",
    "\n",
    "    # output csv\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"executed strategies, saved results in {output_path}\")\n",
    "\n",
    "\n",
    "def grid_search_eth_strategy(file_path, output_folder, nrows=None, min_price=1800, max_price=3600,\n",
    "                             grid_densities=[80, 100, 120], initial_prices=[2400, 2700, 3000],\n",
    "                             time_intervals=[1, 5, 15], max_size=10, grid_unit_size=0.1, free_rate=0.0005):\n",
    "    \"\"\"\n",
    "    grid search over trade stratigies\n",
    "\n",
    "    parameters:\n",
    "        file_path (str): input csv file path\n",
    "        output_folder (str): output csv file path \n",
    "        nrows (int, optional): number of rows to read, default=all\n",
    "        min_price (float): minimum price, default=1800\n",
    "        max_price (float): maximum price, default=3600\n",
    "        grid_densities (list of int): grid density list \n",
    "        initial_prices (list of float): initial price list\n",
    "        time_intervals (list of int): time interval list\n",
    "        max_size (int): maximum trade amount\n",
    "        grid_unit_size (float): amount in every grid trade\n",
    "        free_rate (float): processing fee\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # create output folder\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # generate all combinations\n",
    "    param_combinations = list(itertools.product(grid_densities, initial_prices, time_intervals))\n",
    "\n",
    "    # search thru combinations and call func eth_grid_trading_strategy\n",
    "    for grid_count, initial_price, time_interval in param_combinations:\n",
    "        output_file = os.path.join(output_folder, f\"grid{grid_count}_price{initial_price}_interval{time_interval}.csv\")\n",
    "        eth_grid_trading_strategy(file_path, output_file, nrows=nrows, min_price=min_price, max_price=max_price,\n",
    "                                  grid_count=grid_count, initial_price=initial_price, time_interval=time_interval,\n",
    "                                  max_size=max_size, grid_unit_size=grid_unit_size, free_rate=free_rate)\n",
    "\n",
    "\n",
    "# grid search\n",
    "grid_search_eth_strategy(\n",
    "    file_path='data.csv',\n",
    "    output_folder='simulations',  # output files save in 'simulation' folder\n",
    "    nrows=100000,\n",
    "    min_price=1800,\n",
    "    max_price=3600,\n",
    "    grid_densities=[80, 100, 120],\n",
    "    initial_prices=[2400, 2700, 3000, 3300],\n",
    "    time_intervals=[1, 3, 5, 15],\n",
    "    grid_unit_size=0.1,\n",
    "    max_size=10,\n",
    "    free_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c488b0",
   "metadata": {},
   "source": [
    "# 3. analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7f84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " grid120_price2400_interval15.csv : -330406.2218840271\n",
      " grid80_price3300_interval3.csv : -45385039.19338204\n",
      " grid120_price2400_interval3.csv : -1686974.0479161516\n",
      " grid100_price3000_interval3.csv : -6598808.4621331245\n",
      " grid100_price3000_interval1.csv : -19751423.621732682\n",
      " grid120_price2400_interval1.csv : -5048650.747073352\n",
      " grid80_price3300_interval1.csv : -136174214.927971\n",
      " grid120_price3000_interval15.csv : -1428065.7750180382\n",
      " grid80_price3300_interval5.csv : -27154302.81632778\n",
      " grid100_price3000_interval5.csv : -3910887.7113986462\n",
      " grid80_price2400_interval15.csv : -319398.17878402025\n",
      " grid120_price2400_interval5.csv : -989896.6247950606\n",
      " grid80_price3000_interval15.csv : -1710253.4087797813\n",
      " grid100_price2400_interval15.csv : -328495.709148027\n",
      " grid80_price2400_interval5.csv : -956020.928706035\n",
      " grid100_price2700_interval5.csv : 924748.4201904461\n",
      " grid120_price3300_interval5.csv : -27321372.903712317\n",
      " grid100_price3000_interval15.csv : -1306971.687553931\n",
      " grid100_price2700_interval1.csv : 4515685.7775722\n",
      " grid120_price3300_interval1.csv : -136995027.27604806\n",
      " grid80_price2400_interval1.csv : -4874195.233814836\n",
      " grid80_price2400_interval3.csv : -1629488.997642599\n",
      " grid120_price3300_interval3.csv : -45656158.26578952\n",
      " grid100_price2700_interval3.csv : 1501051.9289711975\n",
      " grid120_price2700_interval5.csv : 1139553.6412144154\n",
      " grid100_price3300_interval5.csv : -26420418.368242368\n",
      " grid80_price3000_interval5.csv : -5120868.700081348\n",
      " grid100_price3300_interval15.csv : -8804750.365014814\n",
      " grid100_price2700_interval15.csv : 309369.2240179954\n",
      " grid100_price3300_interval3.csv : -44150761.749244824\n",
      " grid120_price2700_interval3.csv : 1861667.6416751929\n",
      " grid80_price3000_interval3.csv : -8613972.782506026\n",
      " grid80_price3000_interval1.csv : -25812839.91916892\n",
      " grid120_price2700_interval1.csv : 5594719.848180026\n",
      " grid100_price3300_interval1.csv : -132487369.16378331\n",
      " grid80_price2700_interval1.csv : 4416147.994529337\n",
      " grid120_price3000_interval1.csv : -21608772.430761516\n",
      " grid100_price2400_interval1.csv : -5016593.968243793\n",
      " grid120_price3300_interval15.csv : -9104447.413408667\n",
      " grid100_price2400_interval3.csv : -1676166.304040134\n",
      " grid120_price3000_interval3.csv : -7216126.7644158825\n",
      " grid120_price2700_interval15.csv : 380862.31886048615\n",
      " grid80_price2700_interval3.csv : 1467898.6205242611\n",
      " grid80_price3300_interval15.csv : -9051715.764287934\n",
      " grid120_price3000_interval5.csv : -4276112.352490015\n",
      " grid100_price2400_interval5.csv : -984494.7520995513\n",
      " grid80_price2700_interval5.csv : 904527.8857662342\n",
      " grid80_price2700_interval15.csv : 302770.10972451605\n",
      "file with highest-profit: simulations/grid120_price2700_interval1.csv\n",
      "total profit: 5594719.848180026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_profit(file_path):\n",
    "    # read transaction records\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # initialize wkly profit\n",
    "    weekly_profit = []  \n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # group by week\n",
    "    weekly_data = df.resample('W').last()  # data at end time in each week\n",
    "\n",
    "    # calc profit\n",
    "    for date, week_row in weekly_data.iterrows():\n",
    "        week_price = week_row['close']\n",
    "        position = week_row['Position']\n",
    "        money = week_row['money']\n",
    "\n",
    "        # current crypto value\n",
    "        profit = money + position * week_price\n",
    "        weekly_profit.append([date, profit])\n",
    "\n",
    "    # create df\n",
    "    df_profit = pd.DataFrame(weekly_profit, columns=['Week', 'Profit'])\n",
    "\n",
    "    output_folder = \"analyses\"\n",
    "    if not os.path.exists(\"analyses\"):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    # output\n",
    "    file_path = os.path.basename(file_path)\n",
    "    df_profit.to_csv(f'{output_folder}/analyse_{file_path}.csv', index=False)\n",
    "\n",
    "    return profit\n",
    "\n",
    "\n",
    "# output in csv\n",
    "# df_profit = analyze_profit('simulation.csv')\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def iterate_simulation_files(folder_path):\n",
    "    \"\"\"\n",
    "    search all csv and choose the highest-profit\n",
    "\n",
    "    parameters:\n",
    "        folder_path (str): input folder path\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # if folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"folder {folder_path} doesn't exist\")\n",
    "        return\n",
    "\n",
    "    max_profit = -float('inf')\n",
    "    best_file = None\n",
    "    best_file_profit = None\n",
    "\n",
    "    # search\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        \n",
    "        # check if fild name ends with .csv\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            profit = analyze_profit(file_path)\n",
    "            print(f\" {file_name} : {profit}\")\n",
    "            \n",
    "            # update highest-profit file\n",
    "            if profit is not None and profit > max_profit:\n",
    "                max_profit = profit\n",
    "                best_file = file_path\n",
    "                best_file_profit = profit\n",
    "\n",
    "    # choose the highest-profit file and info\n",
    "    if best_file:\n",
    "        print(f\"file with highest-profit: {best_file}\")\n",
    "        print(f\"total profit: {best_file_profit}\")\n",
    "    else:\n",
    "        print(\"didn't find any\")\n",
    "\n",
    "\n",
    "# search 'simulations' folder\n",
    "iterate_simulation_files('simulations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29637d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a874b8e4",
   "metadata": {},
   "source": [
    "## 3.1 compare profits in one merged table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c001657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " grid120_price2400_interval15.csv : 0.0\n",
      " grid80_price3300_interval3.csv : 4905254.293555549\n",
      " grid120_price2400_interval3.csv : 0.0\n",
      " grid120_price2400_interval1.csv : 0.0\n",
      " grid80_price3300_interval1.csv : 14742225.044197554\n",
      " grid80_price3300_interval5.csv : 2959024.2470566886\n",
      " grid80_price2400_interval15.csv : 0.0\n",
      " grid120_price2400_interval5.csv : 0.0\n",
      " grid100_price2400_interval15.csv : 0.0\n",
      " grid80_price2400_interval5.csv : 0.0\n",
      " grid100_price2700_interval5.csv : 33.50363999999997\n",
      " grid120_price3300_interval5.csv : 2669355.3719449276\n",
      " grid100_price2700_interval1.csv : 17.29674749999994\n",
      " grid120_price3300_interval1.csv : 13309867.547830723\n",
      " grid80_price2400_interval1.csv : 0.0\n",
      " grid80_price2400_interval3.csv : 0.0\n",
      " grid120_price3300_interval3.csv : 4428535.365005691\n",
      " grid100_price2700_interval3.csv : 0.0\n",
      " grid120_price2700_interval5.csv : 33.50363999999997\n",
      " grid100_price3300_interval5.csv : 2630777.3980478854\n",
      " grid100_price3300_interval15.csv : 876925.023692518\n",
      " grid100_price2700_interval15.csv : 0.0\n",
      " grid100_price3300_interval3.csv : 4361653.877108384\n",
      " grid120_price2700_interval3.csv : 0.0\n",
      " grid120_price2700_interval1.csv : 17.29674749999994\n",
      " grid100_price3300_interval1.csv : 13115744.228761008\n",
      " grid80_price2700_interval1.csv : 17.25176999999998\n",
      " grid100_price2400_interval1.csv : 0.0\n",
      " grid120_price3300_interval15.csv : 889740.9851770324\n",
      " grid100_price2400_interval3.csv : 0.0\n",
      " grid120_price2700_interval15.csv : 0.0\n",
      " grid80_price2700_interval3.csv : 0.0\n",
      " grid80_price3300_interval15.csv : 986811.2866210431\n",
      " grid100_price2400_interval5.csv : 0.0\n",
      " grid80_price2700_interval5.csv : 33.50363999999997\n",
      " grid80_price2700_interval15.csv : 0.0\n",
      "file with highest-profit: simulations/grid80_price3300_interval1.csv\n",
      "total profit: 14742225.044197554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def get_strategy(file_path):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        file_path (str): file path\n",
    "\n",
    "    return:\n",
    "        List[int]: num list in file names\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    numbers = re.findall(r'\\d+', file_name)\n",
    "\n",
    "    number_list = [int(num) for num in numbers]\n",
    "\n",
    "    return number_list\n",
    "\n",
    "\n",
    "def analyze_profit(file_path):\n",
    "    # read transaction records\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # initialize wkly profit\n",
    "    weekly_profit = []  \n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # group by week\n",
    "    weekly_data = df.resample('W').last()  # data at end time in each week\n",
    "\n",
    "    # calc profit\n",
    "    for date, week_row in weekly_data.iterrows():\n",
    "        week_price = week_row['close']\n",
    "        position = week_row['Position']\n",
    "        money = week_row['money']\n",
    "\n",
    "        # current crypto value\n",
    "        profit = money + position * week_price\n",
    "        weekly_profit.append([date, profit])\n",
    "\n",
    "    # create df\n",
    "    df_profit = pd.DataFrame(weekly_profit, columns=['Week', 'Profit'])\n",
    "\n",
    "    output_folder = \"analyses\"\n",
    "    if not os.path.exists(\"analyses\"):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    # output\n",
    "    file_path = os.path.basename(file_path)\n",
    "    df_profit.to_csv(f'{output_folder}/analyse_{file_path}.csv', index=False)\n",
    "\n",
    "    return profit ,df_profit\n",
    "\n",
    "# output in csv\n",
    "# df_profit = analyze_profit('simulation.csv')\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def iterate_simulation_files(folder_path):\n",
    "    \"\"\"\n",
    "    search all csv and choose the highest-profit\n",
    "\n",
    "    parameters:\n",
    "        folder_path (str): input folder path\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # if folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"folder {folder_path} doesn't exist\")\n",
    "        return\n",
    "\n",
    "    max_profit = -float('inf')  \n",
    "    best_file = None\n",
    "    best_file_profit = None\n",
    "    strategy_profit = {}\n",
    "    best_strategy = None\n",
    "    df_profits = []\n",
    "    \n",
    "    # search\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        \n",
    "        # check if fild name ends with .csv\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            profit, df_profit = analyze_profit(file_path)\n",
    "            strategy = str(get_strategy(file_path))\n",
    "            df_profit = df_profit.rename(columns={\"Profit\":f\"{str(strategy)}_Profit\"})\n",
    "            print(f\" {file_name} : {profit}\")\n",
    "            strategy_profit[str(strategy)] =  profit\n",
    "            df_profits.append(df_profit)\n",
    "            \n",
    "            # update highest-profit file\n",
    "            if profit is not None and profit > max_profit:\n",
    "                max_profit = profit\n",
    "                best_file = file_path\n",
    "                best_file_profit = profit\n",
    "                best_strategy = strategy\n",
    "\n",
    "    df = pd.concat(df_profits ,axis=1)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    df = df.rename(columns={ f\"{str(best_strategy)}_Profit\": f\"best_{str(best_strategy)}_Profit\" })\n",
    "    df.to_csv(\"analyses/merged_profit.csv\")\n",
    "    \n",
    "    # choose the highest-profit file and info\n",
    "    if best_file:\n",
    "        print(f\"file with highest-profit: {best_file}\")\n",
    "        print(f\"total profit: {best_file_profit}\")\n",
    "    else:\n",
    "        print(\"didn't find any\")\n",
    "\n",
    "\n",
    "# search 'simulations' folder\n",
    "iterate_simulation_files('simulations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce07e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
